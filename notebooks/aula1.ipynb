{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raspagem de dados web com Python\n",
    "\n",
    "Este notebook expõe os conceitos básicos de raspagem de dados web (web scraping) e propõe alguns exercícios.\n",
    "Utilizaremos conceitos pythônicos como funções e controle de fluxo, além de conceitos da Internet como o protocolo HTTP, URLs e de componentes fundamentias da web, como HTML, CSS, JavaScript etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Como funciona a web?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Internet enquanto sistema global de redes de computadores interconectadas\n",
    "#### Redes de computadores\n",
    "![A rede mundial de computadores](internet.png \"Internet\")\n",
    "\n",
    "#### Infraestrutura\n",
    "![Cabos submarinos que conectam os computadores](internet2.png \"Infraestrutura da Internet\")\n",
    "\n",
    "#### Os URLs e o Protocolo HTTP\n",
    "* URL: Uniform Resource Layer -> endereço web\n",
    "* HTTP: Hypertext Transfer Protocol -> fundação da comunicação de dados na web\n",
    "\n",
    "![O protocolo HTTP e o URL sendo usado no Browser](http.png \"HTTP/URL no Browser\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como o navegador transforma os dados recebidos via HTTP em elementos visuais?\n",
    "\n",
    "#### O código-fonte dos websites: HTML, CSS e JavaScript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemplo da página [http://pythonscraping.com/pages/page1.html](http://pythonscraping.com/pages/page1.html)\n",
    "\n",
    "```html\n",
    "<html>\n",
    "<head>\n",
    "<title>A Useful Page</title>\n",
    "</head>\n",
    "<body>\n",
    "<h1>An Interesting Title</h1>\n",
    "<div>\n",
    "Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\n",
    "</div>\n",
    "</body>\n",
    "</html>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Um exemplo mais complexo, com CSS: [https://quotes.toscrape.com](https://quotes.toscrape.com); e outro, com JavaScript: [https://www.globo.com/](https://www.globo.com/)\n",
    "É preciso clicar com o botão direito na página e clicar em `Exibir código-fonte`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do navegador ao código: como ler a web com Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests\n",
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `requests`: fazendo pedidos HTTP com Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "r = requests.get('http://pythonscraping.com/pages/page1.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# biblioteca interna ao Python para fazer prints mais bonitos\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `BeautifulSoup`: transformando HTML em dados estruturados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(r.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.prettify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Navegando pela árvore do HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.div"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raspando a web: um exemplo introdutório\n",
    "\n",
    "Vamos unir as explicações desenvolvidas acima aos nossos conhecimentos de Python para raspar a seguinte página: [https://quotes.toscrape.com/](https://quotes.toscrape.com/). Essa página foi criada pela empresa ScrapingHub, desenvolvedora da biblioteca de web scraping avançado `Scrapy`, com o objetivo de introduzir iniciantes à raspagem de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(\"https://quotes.toscrape.com/\")\n",
    "soup = BeautifulSoup(r.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Como obter a citação do Einstein?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.span.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.small.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Os métodos `find` e `find_all` do `BeautifulSoup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('span', class_='text').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('small', class_=\"author\").text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtendo uma lista de elementos com o find_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('span')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements = soup.find_all('span')\n",
    "elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elements = [elements.text for elements in soup.find_all('span', class_='text')]\n",
    "elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construindo uma `list` de citações e autores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors = [author.text for author in soup.find_all('small', class_='author')]\n",
    "quotes = [quote.text for quote in soup.find_all('span', class_='text')]\n",
    "\n",
    "data = list(zip(authors, quotes))\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construindo uma função que retorna os registros de citações de uma página (autores, citação etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quote_records(soup):\n",
    "    quotes = [quote.text for quote in soup.find_all(\"span\", class_=\"text\")]\n",
    "    authors = [author.text for author in soup.find_all(\"small\", class_=\"author\")]\n",
    "\n",
    "    data = list(zip(authors, quotes))\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "get_quote_records(soup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 1\n",
    "all_data = []\n",
    "\n",
    "while True:\n",
    "    # constrói o objeto `soup`\n",
    "    r = requests.get(f\"https://quotes.toscrape.com/page/{count}\")\n",
    "    soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "\n",
    "    # anexa os dados à list `data`\n",
    "    page_data = get_quote_records(soup)\n",
    "    all_data += page_data\n",
    "\n",
    "    # incrementa o contador\n",
    "    count += 1\n",
    "\n",
    "    # condição de parada: quando não há mais dados\n",
    "    if page_data == []:\n",
    "        break\n",
    "\n",
    "# mostra os dados\n",
    "print(all_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adicionando os dados de `tags`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_divs = soup.find_all(\"div\", class_=\"tags\")\n",
    "\n",
    "all_tags = []\n",
    "for tag_div in tag_divs:\n",
    "    tags = tag_div.find_all(\"a\")\n",
    "    tags = [tag.text for tag in tags]\n",
    "    all_tags.append(tags)\n",
    "\n",
    "all_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encapsulando tudo em fuções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tags(soup):\n",
    "    tag_divs = soup.find_all(\"div\", class_=\"tags\")\n",
    "\n",
    "    all_tags = []\n",
    "    for tag_div in tag_divs:\n",
    "        tags = tag_div.find_all(\"a\")\n",
    "        tags = [tag.text for tag in tags]\n",
    "        all_tags.append(tags)\n",
    "\n",
    "    return all_tags\n",
    "\n",
    "\n",
    "def get_quote_records(soup):\n",
    "    quotes = [quote.text for quote in soup.find_all(\"span\", class_=\"text\")]\n",
    "    authors = [author.text for author in soup.find_all(\"small\", class_=\"author\")]\n",
    "    tags = get_tags(soup)\n",
    "\n",
    "    data = list(zip(authors, quotes, tags))\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "get_quote_records(soup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_quotes(soup):\n",
    "    count = 1\n",
    "    all_data = []\n",
    "\n",
    "    while True:\n",
    "        # constrói o objeto `soup`\n",
    "        r = requests.get(f\"https://quotes.toscrape.com/page/{count}\")\n",
    "        soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "\n",
    "        # anexa os dados à list `data`\n",
    "        page_data = get_quote_records(soup)\n",
    "        all_data += page_data\n",
    "\n",
    "        # incrementa o contador\n",
    "        count += 1\n",
    "\n",
    "        # condição de parada do loop: quando não há mais dados\n",
    "        if page_data == []:\n",
    "            break\n",
    "\n",
    "    return all_data\n",
    "\n",
    "\n",
    "get_all_quotes(soup)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raspando páginas que demandam interação com o browser\n",
    "\n",
    "Nessa seção utilizaremos a biblioteca `helium`, que nos permite interagir com as páginas da web diretamente do Python. Com ele é possível clicar em botões, escrever dados em formulários e muito mais de uma forma muito mais simples que o mais conhecido `selenium`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fazendo login na página com `helium`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install helium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helium import (\n",
    "    start_chrome,\n",
    "    write,\n",
    "    click,\n",
    "    press,\n",
    "    TAB,\n",
    "    ENTER,\n",
    "    kill_browser,\n",
    ")\n",
    "\n",
    "driver = start_chrome(\"https://quotes.toscrape.com/\")\n",
    "click(\"Login\")\n",
    "write(\"a\", into=\"Username\")\n",
    "press(TAB)\n",
    "write(\"b\", into=\"Password\")\n",
    "press(ENTER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes_data = get_all_quotes(soup)\n",
    "quotes_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exportando tudo para uma tabela em CSV com `pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = dict(zip(['authors', 'quotes', 'tags'], zip(*quotes_data)))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('scraped_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando o `pandas` para raspar tabelas de websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_html('https://en.wikipedia.org/wiki/List_of_Copa_Libertadores_finals', flavor='html5lib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[2].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[3].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tecnologias da Web\n",
    "* [https://en.wikipedia.org/wiki/Internet]()\n",
    "* [https://en.wikipedia.org/wiki/URL]()\n",
    "* [https://en.wikipedia.org/wiki/World_Wide_Web]()\n",
    "* [https://en.wikipedia.org/wiki/HTML]()\n",
    "* [https://en.wikipedia.org/wiki/CSS]()\n",
    "* [https://en.wikipedia.org/wiki/JavaScript]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raspagem de dados com Python\n",
    "* MITCHELL, R. [Web Scraping with Python](https://www.oreilly.com/library/view/web-scraping-with/9781491985564/). 2. ed. Sebastopol, CA, O’Reilly Media, Inc., 2018. \n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f2a0f9a9ce29502547ef8b20022140c44c7eb9b587c3771383073f0ed5caa7da"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('.venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
